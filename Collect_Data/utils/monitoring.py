#!/usr/bin/env python3
"""
Module de monitoring centralisÃ© pour DataFlow360
Fournit des mÃ©triques Prometheus pour tous les services

Usage:
    from utils.monitoring import start_metrics_server, crypto_messages_received
    
    start_metrics_server(port=8000)
    crypto_messages_received.labels(source='binance', symbol='BTC').inc()
"""

import logging
import time
import os
from functools import wraps
from prometheus_client import (
    Counter, Gauge, Histogram, Summary,
    start_http_server
)

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] [%(name)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==================== MÃ‰TRIQUES PROMETHEUS ====================

# --- MESSAGES CRYPTO ---
crypto_messages_received = Counter(
    'dataflow_crypto_messages_received_total',
    'Nombre total de messages crypto reÃ§us',
    ['source', 'symbol', 'message_type']
)

# --- PRIX DES CRYPTOS ---
crypto_current_price = Gauge(
    'dataflow_crypto_current_price_usd',
    'Prix actuel de la crypto en USD',
    ['symbol', 'source']
)

crypto_volume_24h = Gauge(
    'dataflow_crypto_volume_24h_usd',
    'Volume de trading 24h en USD',
    ['symbol', 'source']
)

# --- API EXTERNES ---
api_requests_total = Counter(
    'dataflow_api_requests_total',
    'Nombre total de requÃªtes API',
    ['api_name', 'endpoint', 'status_code']
)

api_request_duration = Histogram(
    'dataflow_api_request_duration_seconds',
    'DurÃ©e des requÃªtes API en secondes',
    ['api_name', 'endpoint'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

# --- WEBSOCKETS ---
websocket_connections_active = Gauge(
    'dataflow_websocket_connections_active',
    'Nombre de connexions WebSocket actives',
    ['exchange']
)

websocket_reconnections_total = Counter(
    'dataflow_websocket_reconnections_total',
    'Nombre de reconnexions WebSocket',
    ['exchange', 'reason']
)

websocket_message_latency = Histogram(
    'dataflow_websocket_message_latency_seconds',
    'Latence des messages WebSocket',
    ['exchange', 'symbol'],
    buckets=[0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1.0]
)

# --- KAFKA ---
kafka_messages_sent_total = Counter(
    'dataflow_kafka_messages_sent_total',
    'Messages envoyÃ©s Ã  Kafka',
    ['topic', 'status']
)

kafka_messages_consumed_total = Counter(
    'dataflow_kafka_messages_consumed_total',
    'Messages consommÃ©s depuis Kafka',
    ['topic', 'consumer_group']
)

kafka_consumer_lag = Gauge(
    'dataflow_kafka_consumer_lag_messages',
    'Nombre de messages en retard dans Kafka',
    ['topic', 'partition', 'consumer_group']
)

kafka_processing_duration = Histogram(
    'dataflow_kafka_processing_duration_seconds',
    'DurÃ©e de traitement d\'un message Kafka',
    ['topic'],
    buckets=[0.001, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
)

# --- INFLUXDB ---
influxdb_points_written_total = Counter(
    'dataflow_influxdb_points_written_total',
    'Points de donnÃ©es Ã©crits dans InfluxDB',
    ['measurement', 'status']
)

influxdb_write_duration = Histogram(
    'dataflow_influxdb_write_duration_seconds',
    'DurÃ©e d\'Ã©criture dans InfluxDB',
    ['measurement'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 2.0, 5.0]
)

influxdb_batch_size = Gauge(
    'dataflow_influxdb_batch_size_points',
    'Taille du batch actuel pour InfluxDB',
    ['measurement']
)

# --- HDFS ---
hdfs_files_written_total = Counter(
    'dataflow_hdfs_files_written_total',
    'Fichiers Ã©crits sur HDFS',
    ['path', 'status']
)

hdfs_file_size_bytes = Gauge(
    'dataflow_hdfs_file_size_bytes',
    'Taille des fichiers sur HDFS en bytes',
    ['path']
)

hdfs_write_duration = Histogram(
    'dataflow_hdfs_write_duration_seconds',
    'DurÃ©e d\'Ã©criture sur HDFS',
    ['operation'],
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0]
)

# --- SANTÃ‰ DES SERVICES ---
service_errors_total = Counter(
    'dataflow_service_errors_total',
    'Nombre total d\'erreurs par service',
    ['service', 'error_type']
)

service_health_status = Gauge(
    'dataflow_service_health_status',
    'Statut de santÃ© du service (1=up, 0=down)',
    ['service']
)

service_last_success_timestamp = Gauge(
    'dataflow_service_last_success_timestamp_seconds',
    'Timestamp Unix de la derniÃ¨re opÃ©ration rÃ©ussie',
    ['service']
)

# --- PERFORMANCE ---
operation_summary = Summary(
    'dataflow_operation_summary_seconds',
    'RÃ©sumÃ© des opÃ©rations (quantiles)',
    ['service', 'operation']
)

process_memory_bytes = Gauge(
    'dataflow_process_memory_bytes',
    'Utilisation mÃ©moire du processus en bytes',
    ['service']
)

# ==================== DÃ‰CORATEURS ====================

def track_execution_time(service_name, operation_name=None):
    """
    DÃ©corateur pour mesurer le temps d'exÃ©cution d'une fonction
    
    Usage:
        @track_execution_time('binance', 'fetch_data')
        def fetch_binance_data():
            ...
    """
    def decorator(func):
        op_name = operation_name or func.__name__
        
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                duration = time.time() - start_time
                
                # Enregistrer la durÃ©e
                operation_summary.labels(
                    service=service_name,
                    operation=op_name
                ).observe(duration)
                
                # Mettre Ã  jour le timestamp de succÃ¨s
                service_last_success_timestamp.labels(
                    service=service_name
                ).set(time.time())
                
                logger.debug(f"âœ… [{service_name}] {op_name} completed in {duration:.3f}s")
                return result
                
            except Exception as e:
                duration = time.time() - start_time
                
                # Compter l'erreur
                service_errors_total.labels(
                    service=service_name,
                    error_type=type(e).__name__
                ).inc()
                
                logger.error(f"âŒ [{service_name}] {op_name} failed after {duration:.3f}s: {e}")
                raise
                
        return wrapper
    return decorator


def count_operation(metric_counter, **label_values):
    """
    DÃ©corateur pour compter les opÃ©rations
    
    Usage:
        @count_operation(crypto_messages_received, source='binance', symbol='BTC', message_type='trade')
        def process_btc_message():
            ...
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            result = func(*args, **kwargs)
            metric_counter.labels(**label_values).inc()
            return result
        return wrapper
    return decorator


# ==================== CLASSES HELPERS ====================

class ServiceHealthTracker:
    """Classe pour tracker la santÃ© d'un service"""
    
    def __init__(self, service_name):
        self.service_name = service_name
        service_health_status.labels(service=service_name).set(1)
        logger.info(f"âœ… Health tracker initialisÃ© pour '{service_name}'")
    
    def mark_healthy(self):
        """Marquer le service comme sain"""
        service_health_status.labels(service=self.service_name).set(1)
        service_last_success_timestamp.labels(service=self.service_name).set(time.time())
    
    def mark_unhealthy(self):
        """Marquer le service comme en panne"""
        service_health_status.labels(service=self.service_name).set(0)
        logger.warning(f"âš ï¸  Service '{self.service_name}' marquÃ© comme unhealthy")
    
    def record_error(self, error_type):
        """Enregistrer une erreur"""
        service_errors_total.labels(
            service=self.service_name,
            error_type=error_type
        ).inc()
        logger.error(f"âŒ [{self.service_name}] Erreur enregistrÃ©e: {error_type}")


class APICallTracker:
    """Context manager pour tracker les appels API"""
    
    def __init__(self, api_name, endpoint):
        self.api_name = api_name
        self.endpoint = endpoint
        self.start_time = None
        self.status_code = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        duration = time.time() - self.start_time
        
        # DÃ©terminer le code de statut
        if exc_type is None:
            self.status_code = self.status_code or 200
        else:
            self.status_code = self.status_code or 500
        
        # Enregistrer la requÃªte
        api_requests_total.labels(
            api_name=self.api_name,
            endpoint=self.endpoint,
            status_code=str(self.status_code)
        ).inc()
        
        # Enregistrer la durÃ©e
        api_request_duration.labels(
            api_name=self.api_name,
            endpoint=self.endpoint
        ).observe(duration)
        
        logger.debug(f"ðŸ“¡ API {self.api_name}{self.endpoint} â†’ {self.status_code} ({duration:.3f}s)")
        
        return False  # Ne pas supprimer l'exception


# ==================== FONCTIONS UTILITAIRES ====================

def start_metrics_server(port=8000, service_name=None):
    """
    DÃ©marre le serveur HTTP Prometheus
    
    Args:
        port: Port d'Ã©coute (dÃ©faut: 8000)
        service_name: Nom du service (pour les logs)
    """
    try:
        start_http_server(port, addr="0.0.0.0")
        logger.info(f"âœ… Serveur de mÃ©triques Prometheus dÃ©marrÃ© sur le port {port}")
        logger.info(f"ðŸ“Š MÃ©triques disponibles sur http://0.0.0.0:{port}/metrics")
        
        if service_name:
            service_health_status.labels(service=service_name).set(1)
            logger.info(f"âœ… Service '{service_name}' marquÃ© comme actif")
            
    except OSError as e:
        if "Address already in use" in str(e):
            logger.warning(f"âš ï¸  Port {port} dÃ©jÃ  utilisÃ©, le serveur de mÃ©triques est peut-Ãªtre dÃ©jÃ  dÃ©marrÃ©")
        else:
            logger.error(f"âŒ Impossible de dÃ©marrer le serveur de mÃ©triques: {e}")


def record_crypto_price(symbol, price, source='unknown', volume_24h=None):
    """
    Enregistre le prix d'une crypto
    
    Args:
        symbol: Symbole de la crypto (BTC, ETH, etc.)
        price: Prix en USD
        source: Source des donnÃ©es (binance, coingecko, etc.)
        volume_24h: Volume 24h optionnel
    """
    crypto_current_price.labels(symbol=symbol, source=source).set(price)
    
    if volume_24h is not None:
        crypto_volume_24h.labels(symbol=symbol, source=source).set(volume_24h)
    
    logger.debug(f"ðŸ’¹ Prix mis Ã  jour: {symbol} = ${price:.2f} ({source})")


def get_memory_usage():
    """Retourne l'utilisation mÃ©moire du processus actuel"""
    try:
        import psutil
        process = psutil.Process(os.getpid())
        return process.memory_info().rss
    except ImportError:
        logger.debug("psutil non installÃ©, impossible de mesurer la mÃ©moire")
        return 0
    except Exception as e:
        logger.debug(f"Erreur lors de la mesure mÃ©moire: {e}")
        return 0


def update_process_metrics(service_name):
    """Met Ã  jour les mÃ©triques du processus"""
    memory_bytes = get_memory_usage()
    if memory_bytes > 0:
        process_memory_bytes.labels(service=service_name).set(memory_bytes)
        logger.debug(f"ðŸ’¾ MÃ©moire {service_name}: {memory_bytes/1024/1024:.1f} MB")


# ==================== EXPORT ====================

__all__ = [
    # MÃ©triques
    'crypto_messages_received',
    'crypto_current_price',
    'crypto_volume_24h',
    'api_requests_total',
    'api_request_duration',
    'websocket_connections_active',
    'websocket_reconnections_total',
    'websocket_message_latency',
    'kafka_messages_sent_total',
    'kafka_messages_consumed_total',
    'kafka_consumer_lag',
    'kafka_processing_duration',
    'influxdb_points_written_total',
    'influxdb_write_duration',
    'influxdb_batch_size',
    'hdfs_files_written_total',
    'hdfs_file_size_bytes',
    'hdfs_write_duration',
    'service_errors_total',
    'service_health_status',
    'service_last_success_timestamp',
    'operation_summary',
    'process_memory_bytes',
    
    # DÃ©corateurs
    'track_execution_time',
    'count_operation',
    
    # Classes
    'ServiceHealthTracker',
    'APICallTracker',
    
    # Fonctions
    'start_metrics_server',
    'record_crypto_price',
    'update_process_metrics',
    'get_memory_usage',
]


# ==================== EXEMPLE D'UTILISATION ====================

if __name__ == '__main__':
    """
    Exemple d'utilisation du module
    """
    print("="*60)
    print("ðŸ§ª TEST DU MODULE MONITORING")
    print("="*60)
    
    # DÃ©marrer le serveur de mÃ©triques
    start_metrics_server(8000, 'test_service')
    
    # CrÃ©er un health tracker
    health = ServiceHealthTracker('test_service')
    
    # Simuler des opÃ©rations
    @track_execution_time('test_service', 'test_operation')
    def test_function():
        time.sleep(0.1)
        return "OK"
    
    # ExÃ©cuter plusieurs fois
    for i in range(5):
        print(f"\nðŸ”„ Test #{i+1}")
        
        # Appeler la fonction
        result = test_function()
        
        # Simuler rÃ©ception de messages
        crypto_messages_received.labels(
            source='binance',
            symbol='BTCUSDT',
            message_type='test'
        ).inc()
        
        # Mettre Ã  jour un prix
        record_crypto_price('BTCUSDT', 50000 + i*100, 'binance')
        
        # Marquer comme sain
        health.mark_healthy()
        
        time.sleep(1)
    
    # Afficher le lien vers les mÃ©triques
    print(f"\n{'='*60}")
    print("âœ… Test terminÃ© !")
    print(f"ðŸ“Š MÃ©triques disponibles: http://localhost:8000/metrics")
    print(f"{'='*60}")
    print("\nAppuyez sur Ctrl+C pour arrÃªter...")
    
    try:
        while True:
            update_process_metrics('test_service')
            time.sleep(10)
    except KeyboardInterrupt:
        print("\nðŸ‘‹ ArrÃªt du test")