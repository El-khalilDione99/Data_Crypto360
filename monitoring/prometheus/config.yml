global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'dataflow360'
    environment: 'production'

scrape_configs:
  # Prometheus lui-même
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter (métriques système)
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  # cAdvisor (métriques conteneurs)
  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  # Kafka Exporter
  - job_name: 'kafka-exporter'
    static_configs:
      - targets: ['kafka-exporter:9308']

  # InfluxDB
  - job_name: 'influxdb'
    static_configs:
      - targets: ['influxdb:8086']
    metrics_path: '/metrics'

  # Services Python avec métriques custom
  - job_name: 'dataflow-binance'
    static_configs:
      - targets: ['binance_kafka:8000']
        labels:
          service: 'binance_kafka'
          type: 'websocket'

  - job_name: 'dataflow-coingecko'
    static_configs:
      - targets: ['coingo_kafka:8000']
        labels:
          service: 'coingecko_kafka'
          type: 'api'

  - job_name: 'dataflow-kafka-influx'
    static_configs:
      - targets: ['kafka_to_influx:8000']
        labels:
          service: 'kafka_to_influx'
          type: 'consumer'

  - job_name: 'dataflow-csv-hdfs'
    static_configs:
      - targets: ['crypto_batch:8000']
        labels:
          service: 'crypto_batch'
          type: 'batch'

  # HDFS Namenode - Désactivé car JMX n'est pas compatible avec Prometheus
  # Pour monitorer HDFS, utilisez JMX Exporter ou Hadoop metrics
  # - job_name: 'hdfs-namenode'
  #   static_configs:
  #     - targets: ['namenode:50070']
  #   metrics_path: '/jmx'