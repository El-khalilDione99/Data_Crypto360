# Configuration Promtail pour DataFlow360
# Promtail = Agent qui collecte les logs et les envoie à Loki

server:
  http_listen_port: 9080
  grpc_listen_port: 0
  log_level: info

# Fichier de positions pour suivre où on en est dans la lecture des logs
positions:
  filename: /tmp/positions.yaml

# Clients Loki (où envoyer les logs)
clients:
  - url: http://loki:3100/loki/api/v1/push
    backoff_config:
      min_period: 500ms
      max_period: 5m
      max_retries: 10
    # Batch les logs avant de les envoyer
    batchsize: 1048576  # 1MB
    batchwait: 1s
    timeout: 10s

# Configuration de la collecte des logs
scrape_configs:
  # ==========================================
  # Logs des conteneurs Docker
  # ==========================================
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
        filters:
          - name: label
            values: ["logging=promtail"]
    
    relabel_configs:
      # Extraire le nom du conteneur
      - source_labels: ['__meta_docker_container_name']
        target_label: 'container'
        regex: '/(.*)'
      
      # Extraire l'ID du conteneur
      - source_labels: ['__meta_docker_container_id']
        target_label: 'container_id'
        regex: '(.{12}).*'
        replacement: '$1'
      
      # Extraire le nom du service depuis docker-compose
      - source_labels: ['__meta_docker_container_label_com_docker_compose_service']
        target_label: 'service'
      
      # Extraire le nom du projet
      - source_labels: ['__meta_docker_container_label_com_docker_compose_project']
        target_label: 'project'
      
      # Filtrer uniquement nos services de données
      - source_labels: ['__meta_docker_container_name']
        regex: '.*(binance_kafka|coingo_kafka|kafka_to_influx|crypto_batch|namenode|datanode|kafka|zookeeper|influxdb).*'
        action: keep
    
    # Pipeline de traitement des logs
    pipeline_stages:
      # Étape 1 : Parser les logs JSON si présents
      - json:
          expressions:
            level: level
            message: message
            timestamp: timestamp
            service: service
          source: message
      
      # Étape 2 : Parser les logs texte classiques
      - regex:
          expression: '^(?P<timestamp>\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2})[,\s]+\[?(?P<level>[A-Z]+)\]?\s+(?P<message>.*)$'
          source: message
      
      # Étape 3 : Extraire des métriques des logs
      - metrics:
          # Compter les erreurs
          error_total:
            type: Counter
            description: "Nombre total d'erreurs dans les logs"
            source: level
            config:
              value: "ERROR"
              action: inc
          
          # Compter les warnings
          warning_total:
            type: Counter
            description: "Nombre total de warnings"
            source: level
            config:
              value: "WARNING"
              action: inc
          
          # Compter les messages de succès
          success_total:
            type: Counter
            description: "Nombre de messages de succès"
            source: message
            config:
              matches: "✅|success|réussi"
              action: inc
      
      # Étape 4 : Ajouter des labels
      - labels:
          level:
          container:
          service:
          project:
      
      # Étape 5 : Standardiser le timestamp
      - timestamp:
          source: timestamp
          format: '2006-01-02 15:04:05'
          fallback_formats:
            - RFC3339
            - RFC3339Nano
          action_on_failure: skip

  # ==========================================
  # Logs des services Python spécifiques
  # ==========================================
  - job_name: dataflow_services
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        target_label: 'container'
        regex: '/(.*)'
      
      # Filtrer uniquement nos services Python
      - source_labels: ['__meta_docker_container_name']
        regex: '.*(binance_kafka|coingo_kafka|kafka_to_influx|crypto_batch).*'
        action: keep
    
    pipeline_stages:
      # Parser les logs Python avec émojis
      - regex:
          expression: '^(?P<timestamp>.*?)\s+\[(?P<level>.*?)\]\s+\[(?P<logger>.*?)\]\s+(?P<emoji>[\p{So}\p{Sk}]*)\s*(?P<message>.*)$'
      
      # Détecter les patterns spécifiques
      - match:
          selector: '{container=~"binance.*"}'
          stages:
            - regex:
                expression: '(?P<symbol>[A-Z]{3,10}USDT)\s+→\s+\$?(?P<price>[\d,\.]+)'
                source: message
            - labels:
                symbol:
      
      - match:
          selector: '{container=~".*kafka.*"}'
          stages:
            - regex:
                expression: '(?P<count>\d+)\s+(?:messages?|points?)\s+(?:envoyés?|écrits?|consommés?)'
                source: message
      
      # Métriques spécifiques
      - metrics:
          # Messages Kafka
          kafka_messages_logged:
            type: Counter
            description: "Messages Kafka mentionnés dans les logs"
            source: message
            config:
              matches: "messages? (envoyés?|écrits?|consommés?)"
              action: inc
          
          # Erreurs de connexion
          connection_errors:
            type: Counter
            description: "Erreurs de connexion"
            source: message
            config:
              matches: "connexion|connection|timeout"
              action: inc
      
      - labels:
          level:
          container:
          logger:

  # ==========================================
  # Logs systèmes (optionnel)
  # ==========================================
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: system
          __path__: /var/log/syslog
    
    pipeline_stages:
      - match:
          selector: '{job="system"}'
          stages:
            - regex:
                expression: '^(?P<timestamp>\w+\s+\d+\s+\d+:\d+:\d+)\s+(?P<hostname>\S+)\s+(?P<app>\S+):\s+(?P<message>.*)$'